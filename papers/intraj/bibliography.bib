@article{DBLP:journals/cacm/Knuth74,
  author    = {Donald E. Knuth},
  title     = {{Computer Programming as an Art}},
  journal   = {Commun. {ACM}},
  volume    = {17},
  number    = {12},
  pages     = {667--673},
  year      = {1974},
  doi       = {10.1145/361604.361612},
  timestamp = {Tue, 07 Jun 2011 16:50:57 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/cacm/Knuth74},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{DBLP:journals/cacm/Dijkstra68a,
  author    = {Edsger W. Dijkstra},
  title     = {Letters to the editor: go to statement considered harmful},
  journal   = {Commun. {ACM}},
  volume    = {11},
  number    = {3},
  pages     = {147--148},
  year      = {1968},
  doi       = {10.1145/362929.362947},
  timestamp = {Thu, 09 Feb 2006 13:19:49 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/cacm/Dijkstra68a},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@book{DBLP:books/mk/GrayR93,
  author    = {Jim Gray and
               Andreas Reuter},
  title     = {Transaction Processing: Concepts and Techniques},
  publisher = {Morgan Kaufmann},
  year      = {1993},
  isbn      = {1-55860-190-2},
  timestamp = {Thu, 05 Nov 2015 19:53:28 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/books/mk/GrayR93},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}



@inproceedings{DBLP:conf/focs/HopcroftPV75,
  author    = {{John E.} Hopcroft and
               {Wolfgang J.} Paul and
               {Leslie G.} Valiant},
  title     = {On Time versus Space and Related Problems},
  booktitle = {16th Annual Symposium on Foundations of Computer Science, Berkeley,
               California, USA, October 13-15, 1975},
  pages     = {57--64},
  year      = {1975},
  crossref  = {DBLP:conf/focs/FOCS16},
  doi       = {10.1109/SFCS.1975.23},
  timestamp = {Tue, 16 Dec 2014 09:57:24 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/focs/HopcroftPV75},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@proceedings{DBLP:conf/focs/FOCS16,
  title     = {16th Annual Symposium on Foundations of Computer Science, Berkeley,
               California, USA, October 13-15, 1975},
  publisher = {{IEEE} Computer Society},
  year      = {1975},
  timestamp = {Mon, 15 Dec 2014 18:48:44 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/focs/FOCS16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{hovemeyer2005evaluating,
  title     = {Evaluating and tuning a static analysis to find null pointer bugs},
  author    = {Hovemeyer, David and Spacco, Jaime and Pugh, William},
  booktitle = {Proceedings of the 6th ACM SIGPLAN-SIGSOFT workshop on Program analysis for software tools and engineering},
  pages     = {13--19},
  year      = {2005}
}

@inproceedings{smith2015questions,
  title     = {Questions developers ask while diagnosing potential security vulnerabilities with static analysis},
  author    = {Smith, Justin and Johnson, Brittany and Murphy-Hill, Emerson and Chu, Bill and Lipford, Heather Richter},
  booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
  pages     = {248--259},
  year      = {2015}
}

@article{10.1016/j.scico.2012.02.002,
  author     = {S\"{o}derberg, Emma and Ekman, Torbj\"{o}rn and Hedin, G\"{o}rel and Magnusson, Eva},
  title      = {Extensible Intraprocedural Flow Analysis at the Abstract Syntax Tree Level},
  year       = {2013},
  issue_date = {October, 2013},
  publisher  = {Elsevier North-Holland, Inc.},
  address    = {USA},
  volume     = {78},
  number     = {10},
  issn       = {0167-6423},
  url        = {https://doi.org/10.1016/j.scico.2012.02.002},
  doi        = {10.1016/j.scico.2012.02.002},
  abstract   = {We have developed a new approach for implementing precise intraprocedural control-flow and dataflow analyses at the abstract syntax tree level. Our approach is declarative, making use of reference attribute grammars augmented with circular attributes and collection attributes. This results in concise executable specifications of the analyses, allowing extensions both to the language and with further source code analyses. To evaluate the new approach, we have implemented control flow, dataflow and dead assignment analyses for Java, by extending the JastAdd Extensible Java Compiler. We have compared our results to several well-known analysis frameworks and tools, using a set of Java programs as benchmarks. These results show that our approach performs well concerning both efficiency and preciseness.},
  journal    = {Sci. Comput. Program.},
  month      = oct,
  pages      = {1809–1827},
  numpages   = {19},
  keywords   = {Compiler, Declarative, Dataflow, Attribute grammars, Analysis, Java, Control-flow}
}




@inproceedings{ekman2007jastadd,
  title     = {The jastadd extensible java compiler},
  author    = {Ekman, Torbj{\"o}rn and Hedin, G{\"o}rel},
  booktitle = {Proceedings of the 22nd annual ACM SIGPLAN conference on Object-oriented programming systems and applications},
  pages     = {1--18},
  year      = {2007}
}


@article{hedin2000rags,
  author    = {G{\"{o}}rel Hedin},
  title     = {Reference Attributed Grammars},
  journal   = {Informatica (Slovenia)},
  volume    = {24},
  number    = {3},
  year      = {2000},
  biburl    = {https://dblp.org/rec/journals/informaticaSI/Hedin00.bib}
}

@article{a42d66bd599e4d45b783a5de8b652497,
	title = "Circular Reference Attributed Grammars - their Evaluation and Applications",
	abstract = "This paper presents a combination of Reference Attributed Grammars (RAGs) and Circular Attribute Grammars (CAGs). While RAGs allow the direct and easy specification of non-locally dependent information, CAGs allow iterative fixed-point computations to be expressed directly using recursive (circular) equations. We demonstrate how the combined formalism, Circular Reference Attributed Grammars (CRAGs), can take advantage of both these strengths, making it possible to express solutions to many problems in an easy way. We exemplify with the specification and computation of the nullable, first, and follow sets used in parser construction, a problem which is highly recursive and normally programmed by hand using an iterative algorithm. We also present a general demand-driven evaluation algorithm for CRAGs and some optimizations of it. The approach has been implemented and experimental results include computations on a series of grammars including that of Java 1.2. We also revisit some of the classical examples of CAGs and show how their solutions are facilitated by CRAGs.",
	keywords = "fixed-point computations, Attribute grammars, Circular grammars",
	author = "Eva Magnusson and G{\"o}rel Hedin",
	year = "2007",
	doi = "10.1016/j.scico.2005.06.005",
	language = "English",
	volume = "68",
	pages = "21--37",
	journal = "Science of Computer Programming",
	issn = "0167-6423",
	publisher = "Elsevier",
	number = "1",
}

@article{hedin2003jastadd,
	title={JastAdd—an aspect-oriented compiler construction system},
	author={Hedin, G{\"o}rel and Magnusson, Eva},
	journal={Science of Computer Programming},
	volume={47},
	number={1},
	pages={37--58},
	year={2003},
	publisher={Elsevier}
}

@article{magnusson2007circular,
  title={Circular reference attributed grammars—their evaluation and applications},
  author={Magnusson, Eva and Hedin, G{\"o}rel},
  journal={Science of Computer Programming},
  volume={68},
  number={1},
  pages={21--37},
  year={2007},
  publisher={Elsevier}
}

@inproceedings{magnusson2007extending,
  title={Extending Attribute Grammars with Collection Attributes--Evaluation and Applications},
  author={Magnusson, Eva and Ekman, Torbjorn and Hedin, Gorel},
  booktitle={Seventh IEEE International Working Conference on Source Code Analysis and Manipulation (SCAM 2007)},
  pages={69--80},
  year={2007},
  organization={IEEE}
}

@article{choi1999efficient,
  title={Efficient and precise modeling of exceptions for the analysis of Java programs},
  author={Choi, Jong-Deok and Grove, David and Hind, Michael and Sarkar, Vivek},
  journal={ACM SIGSOFT Software Engineering Notes},
  volume={24},
  number={5},
  pages={21--31},
  year={1999},
  publisher={ACM New York, NY, USA}
}

@article{amighi2016provably,
  title={Provably correct control flow graphs from Java bytecode programs with exceptions},
  author={Amighi, Afshin and de Carvalho Gomes, Pedro and Gurov, Dilian and Huisman, Marieke},
  journal={International journal on software tools for technology transfer},
  volume={18},
  number={6},
  pages={653--684},
  year={2016},
  publisher={Springer}
}

@inproceedings{jo2004constructing,
  title={Constructing control flow graph for java by decoupling exception flow from normal flow},
  author={Jo, Jang-Wu and Chang, Byeong-Mo},
  booktitle={International Conference on Computational Science and Its Applications},
  pages={106--113},
  year={2004},
  organization={Springer}
}

@inproceedings{helm2020modular,
  title={Modular collaborative program analysis in OPAL},
  author={Helm, Dominik and K{\"u}bler, Florian and Reif, Michael and Eichberg, Michael and Mezini, Mira},
  booktitle={Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages={184--196},
  year={2020}
}

@phdthesis{szaboincrementalizing,
  title={Incrementalizing Static Analyses in Datalog},
  author={Szab{\'o}, Tam{\'a}s},
  school={Johannes Gutenberg-Universit{\"a}t Mainz}
}

@article{vogt1989higher,
  title={Higher order attribute grammars},
  author={Vogt, Harald H and Swierstra, S Doaitse and Kuiper, Matthijs F},
  journal={ACM SIGPLAN Notices},
  volume={24},
  number={7},
  pages={131--145},
  year={1989},
  publisher={ACM New York, NY, USA}
}

@inproceedings{fors2020patterns,
  author    = {Niklas Fors and
               Emma S{\"{o}}derberg and
               G{\"{o}}rel Hedin},
  editor    = {Ralf L{\"{a}}mmel and
               Laurence Tratt and
               Juan de Lara},
  title     = {Principles and patterns of JastAdd-style reference attribute grammars},
  booktitle = {Proceedings of the 13th {ACM} {SIGPLAN} International Conference on
               Software Language Engineering, {SLE} 2020, Virtual Event, USA, November
               16-17, 2020},
  pages     = {86--100},
  publisher = {{ACM}},
  year      = {2020},
  url       = {https://doi.org/10.1145/3426425.3426934},
  doi       = {10.1145/3426425.3426934}
}

@inproceedings{cousot1977ai,
  author = {Cousot, Patrick and Cousot, Radhia},
  title = {Abstract Interpretation: A Unified Lattice Model for Static Analysis of Programs by Construction or Approximation of Fixpoints},
  year = {1977},
  isbn = {9781450373500},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/512950.512973},
  doi = {10.1145/512950.512973},
  abstract = {A program denotes computations in some universe of objects. Abstract interpretation of programs consists in using that denotation to describe computations in another universe of abstract objects, so that the results of abstract execution give some information on the actual computations. An intuitive example (which we borrow from Sintzoff [72]) is the rule of signs. The text -1515 * 17 may be understood to denote computations on the abstract universe {(+), (-), (±)} where the semantics of arithmetic operators is defined by the rule of signs. The abstract execution -1515 * 17 → -(+) * (+) → (-) * (+) → (-), proves that -1515 * 17 is a negative number. Abstract interpretation is concerned by a particular underlying structure of the usual universe of computations (the sign, in our example). It gives a summary of some facets of the actual executions of a program. In general this summary is simple to obtain but inaccurate (e.g. -1515 + 17 → -(+) + (+) → (-) + (+) → (±)). Despite its fundamentally incomplete results abstract interpretation allows the programmer or the compiler to answer questions which do not need full knowledge of program executions or which tolerate an imprecise answer, (e.g. partial correctness proofs of programs ignoring the termination problems, type checking, program optimizations which are not carried in the absence of certainty about their feasibility, …).},
  booktitle = {Proceedings of the 4th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
  pages = {238--252},
  numpages = {15},
  location = {Los Angeles, California},
  series = {POPL '77}
}

@article{vanwyk2010silver,
  title = {Silver: An extensible attribute grammar system},
  journal = {Science of Computer Programming},
  volume = {75},
  number = {1},
  pages = {39-54},
  year = {2010},
  note = {Special Issue on ETAPS 2006 and 2007 Workshops on Language Descriptions, Tools, and Applications (LDTA ’06 and ’07)},
  issn = {0167-6423},
  doi = {https://doi.org/10.1016/j.scico.2009.07.004},
  url = {https://www.sciencedirect.com/science/article/pii/S0167642309001099},
  author = {Eric {Van Wyk} and Derek Bodin and Jimin Gao and Lijesh Krishnan},
  keywords = {Extensible languages, Extensible compilers, Attribute grammars, Forwarding, Silver attribute grammar system},
  abstract = {Attribute grammar specification languages, like many domain-specific languages, offer significant advantages to their users, such as high-level declarative constructs and domain-specific analyses. Despite these advantages, attribute grammars are often not adopted to the degree that their proponents envision. One practical obstacle to their adoption is a perceived lack of both domain-specific and general purpose language features needed to address the many different aspects of a problem. Here we describe Silver, an extensible attribute grammar specification system, and show how it can be extended with general purpose features such as pattern matching and domain-specific features such as collection attributes and constructs for supporting data-flow analysis of imperative programs. The result is an attribute grammar specification language with a rich set of language features. Silver is implemented in itself by a Silver attribute grammar and utilizes forwarding to implement the extensions in a cost-effective manner.}
}

@article{vanwyk2007flow,
  title={Using verified data-flow analysis-based optimizations in attribute grammars},
  author={Van Wyk, Eric and Krishnan, Lijesh},
  journal={Electronic Notes in Theoretical Computer Science},
  volume={176},
  number={3},
  pages={109--122},
  year={2007},
  publisher={Elsevier}
}

@inproceedings{dura2019metadl,
  title={MetaDL: Analysing Datalog in Datalog},
  author={Dura, Alexandru and Balldin, Hampus and Reichenbach, Christoph},
  booktitle={Proceedings of the 8th ACM SIGPLAN International Workshop on State Of the Art in Program Analysis},
  pages={38--43},
  year={2019},
  organization={ACM}
}

@inproceedings{deroover2011soul,
  author = {De Roover, Coen and Noguera, Carlos and Kellens, Andy and Jonckers, Vivane},
  title = {The SOUL Tool Suite for Querying Programs in Symbiosis with Eclipse},
  year = {2011},
  isbn = {9781450309356},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/2093157.2093168},
  booktitle = {Proceedings of the 9th International Conference on Principles and Practice of Programming in Java},
  pages = {71--80},
  numpages = {10},
  keywords = {logic programming, program analysis, integrated development environments, program queries, software engineering tools},
  location = {Kongens Lyngby, Denmark},
  series = {PPPJ '11}
}

@article{madsen2016datalog,
  title={From Datalog to flix: a declarative language for fixed points on lattices},
  author={Madsen, Magnus and Yee, Ming-Ho and Lhot{\'a}k, Ond{\v{r}}ej},
  journal={ACM SIGPLAN Notices},
  volume={51},
  number={6},
  pages={194--208},
  year={2016},
  publisher={ACM New York, NY, USA}
}

@article{madsen2020fixpoints,
  title={Fixpoints for the masses: programming with first-class Datalog constraints},
  author={Madsen, Magnus and Lhot{\'a}k, Ond{\v{r}}ej},
  journal={Proceedings of the ACM on Programming Languages},
  volume={4},
  number={OOPSLA},
  pages={1--28},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{smits2020flowspec,
 title = {FlowSpec: A declarative specification language for intra-procedural flow-Sensitive data-flow analysis},
  journal = {Journal of Computer Languages},
  volume = {57},
  pages = {100924},
  year = {2020},
  issn = {2590-1184},
  doi = {https://doi.org/10.1016/j.cola.2019.100924},
  url = {https://www.sciencedirect.com/science/article/pii/S2590118419300474},
  author = {Jeff Smits and Guido Wachsmuth and Eelco Visser},
  abstract = {Data-flow analysis is the static analysis of programs to estimate their approximate run-time behavior or approximate intermediate run-time values. It is an integral part of modern language specifications and compilers. In the specification of static semantics of programming languages, the concept of data-flow allows the description of well-formedness such as definite assignment of a local variable before its first use. In the implementation of compiler back-ends, data-flow analyses inform optimizations. Data-flow analysis has an established theoretical foundation. What lags behind is implementations of data-flow analysis in compilers, which are usually ad-hoc. This makes such implementations difficult to extend and maintain. In previous work researchers have proposed higher-level formalisms suitable for whole-program analysis in a separate tool, incremental analysis within editors, or bound to a specific intermediate representation. In this paper, we present FlowSpec, an executable formalism for specification of data-flow analysis. FlowSpec is a domain-specific language that enables direct and concise specification of data-flow analysis for programming languages, designed to express flow-sensitive, intra-procedural analyses. We define the formal semantics of FlowSpec in terms of monotone frameworks. We describe the design of FlowSpec using examples of standard analyses. We also include a description of our implementation of FlowSpec. In a case study we evaluate FlowSpec with the static analyses for Green-Marl, a domain-specific programming language for graph analytics.}
}

@article{lerner2005automated,
  title={Automated soundness proofs for dataflow analyses and transformations via local rules},
  author={Lerner, Sorin and Millstein, Todd and Rice, Erika and Chambers, Craig},
  journal={ACM SIGPLAN Notices},
  volume={40},
  number={1},
  pages={364--377},
  year={2005},
  publisher={ACM New York, NY, USA}
}

@inproceedings{deroover2011soulsummary,
  title = "A Logic Meta-Programming Foundation for Example-Driven Pattern Detection in Object-Oriented Programs",
  abstract = "This paper summarizes the doctoral dissertation in which we introduced an example-driven approach to pattern detection. This approach enables specifying pattern characteristics in a familiar language: through a code excerpt that corresponds to their prototypical implementation. Such excerpts are matched against the program under investigation according to various matching strategies that vary in leniency. Each match is quantified by the extent to which it exhibits the exemplified characteristics. The smaller this extent, the more likely the match is a false positive --thus establishing a ranking which facilitates assessing a large amount of matches. Unique to the matching process is that it incorporates whole-program analyses in its comparison of individual program elements. This way, we are able to recall implicit implementation variants (i.e., those implied by the semantics of the programming language) of a pattern of which only the prototypical implementation has been exemplified.",
  keywords = "logic meta programming, pattern detection, program querying, static analysis",
  author = "{De Roover}, Coen",
  year = "2011",
  language = "English",
  isbn = "978-1-4577-0663-9",
  series = "Proceedings of the 27th IEEE International Conference on Software Maintenance (ICSM 2011)",
  booktitle = "Proceedings of the 27th IEEE International Conference on Software Maintenance (ICSM 2011)",
}

@inproceedings{bravenboer09doop,
    abstract = {We present the DOOP framework for points-to analysis of Java programs. DOOP builds on the idea of specifying pointer analysis algorithms declaratively, using Datalog: a logic-based language for defining (recursive) relations. We carry the declarative approach further than past work by describing the full end-to-end analysis in Datalog and optimizing aggressively using a novel technique specifically targeting highly recursive Datalog programs.},
    address = {New York, NY, USA},
    author = {Bravenboer, Martin and Smaragdakis, Yannis},
    booktitle = {Proceedings of OOPSLA '09},
    citeulike-article-id = {6210299},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1640089.1640108},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1640089.1640108},
    isbn = {978-1-60558-766-0},
    keywords = {forward-chaining, logic-programming, program-analysis, semi-naive-evaluation},
    location = {Orlando, Florida, USA},
    pages = {243--262},
    posted-at = {2009-11-25 15:19:11},
    priority = {0},
    publisher = {ACM},
    title = {Strictly declarative specification of sophisticated points-to analyses},
    year = {2009}
}



@inproceedings{kildall1973dataflow,
  author = {Kildall, Gary A.},
  title = {A Unified Approach to Global Program Optimization},
  year = {1973},
  isbn = {9781450373494},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/512927.512945},
  doi = {10.1145/512927.512945},
  abstract = {A technique is presented for global analysis of program structure in order to perform compile time optimization of object code generated for expressions. The global expression optimization presented includes constant propagation, common subexpression elimination, elimination of redundant register load operations, and live expression analysis. A general purpose program flow analysis algorithm is developed which depends upon the existence of an "optimizing function." The algorithm is defined formally using a directed graph model of program flow structure, and is shown to be correct. Several optimizing functions are defined which, when used in conjunction with the flow analysis algorithm, provide the various forms of code optimization. The flow analysis algorithm is sufficiently general that additional functions can easily be defined for other forms of global code optimization.},
  booktitle = {Proceedings of the 1st Annual ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
  pages = {194–206},
  numpages = {13},
  location = {Boston, Massachusetts},
  series = {POPL '73}
}

@inproceedings{bodden2012inter,
  title={Inter-procedural data-flow analysis with ifds/ide and soot},
  author={Bodden, Eric},
  booktitle={Proceedings of the ACM SIGPLAN International Workshop on State of the Art in Java Program analysis},
  pages={3--8},
  year={2012}
}

@article{sagiv1996ide,
  title={Precise interprocedural dataflow analysis with applications to constant propagation},
  author={Sagiv, Mooly and Reps, Thomas and Horwitz, Susan},
  journal={Theoretical Computer Science},
  volume={167},
  number={1-2},
  pages={131--170},
  year={1996},
  publisher={Elsevier}
}

@inproceedings{vallee-rai10soot,
 author = {Vall{\'e}e-Rai, Raja and Co, Phong and Gagnon, Etienne and Hendren, Laurie and Lam, Patrick and Sundaresan, Vijay},
 title = {Soot: A Java Bytecode Optimization Framework},
 booktitle = {CASCON First Decade High Impact Papers},
 series = {CASCON '10},
 year = {2010},
 location = {Toronto, Ontario, Canada},
 pages = {214--224},
 numpages = {11},
 url = {http://dx.doi.org/10.1145/1925805.1925818},
 doi = {10.1145/1925805.1925818},
 acmid = {1925818},
 publisher = {IBM Corp.},
 address = {Riverton, NJ, USA},
}

@article{spaeth2019pda,
  author = {Sp\"{a}th, Johannes and Ali, Karim and Bodden, Eric},
  title = {Context-, Flow-, and Field-Sensitive Data-Flow Analysis Using Synchronized Pushdown Systems},
  year = {2019},
  issue_date = {January 2019},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {3},
  number = {POPL},
  url = {https://doi.org/10.1145/3290361},
  doi = {10.1145/3290361},
  abstract = {Precise static analyses are context-, field- and flow-sensitive. Context- and field-sensitivity are both expressible as context-free language (CFL) reachability problems. Solving both CFL problems along the same data-flow path is undecidable, which is why most flow-sensitive data-flow analyses over-approximate field-sensitivity through k-limited access-path, or through access graphs. Unfortunately, as our experience and this paper show, both representations do not scale very well when used to analyze programs with recursive data structures. Any single CFL-reachability problem is efficiently solvable, by means of a pushdown system. This work thus introduces the concept of synchronized pushdown systems (SPDS). SPDS encode both procedure calls/returns and field stores/loads as separate but “synchronized” CFL reachability problems. An SPDS solves both individual problems precisely, and approximation occurs only in corner cases that are apparently rare in practice: at statements where both problems are satisfied but not along the same data-flow path. SPDS are also efficient: formal complexity analysis shows that SPDS shift the complexity from |F|3k under k-limiting to |S||F|2, where F is the set of fields and S the set of statements involved in a data-flow. Our evaluation using DaCapo shows this shift to pay off in practice: SPDS are almost as efficient as k-limiting with k=1 although their precision equals k=∞. For a typestate analysis SPDS accelerate the analysis up to 83\texttimes{} for data-flows of objects that involve many field accesses but span rather few methods. We conclude that SPDS can provide high precision and further improve scalability, in particularly when used in analyses that expose rather local data flows.},
  journal = {Proc. ACM Program. Lang.},
  month = jan,
  articleno = {48},
  numpages = {29},
  keywords = {aliasing, static analysis, access paths, pushdown system, data-flow}
}

@misc{fink2012wala,
  title={WALA--The TJ Watson Libraries for Analysis},
  author={Fink, Stephen and Dolby, Julian},
  year={2012}
}

@inproceedings{smaragdakis2010using,
  title={Using Datalog for fast and easy program analysis},
  author={Smaragdakis, Yannis and Bravenboer, Martin},
  booktitle={International Datalog 2.0 Workshop},
  pages={245--251},
  year={2010},
  organization={Springer}
}

@inproceedings{lhotak03scaling,
  title={Scaling Java points-to analysis using Spark},
  author={Lhot{\'a}k, Ond{\v{r}}ej and Hendren, Laurie},
  booktitle={International Conference on Compiler Construction},
  pages={153--169},
  year={2003},
  organization={Springer}
}
@article{szabo2018inca,
  author = {Szab\'{o}, Tam\'{a}s and Bergmann, G\'{a}bor and Erdweg, Sebastian and Voelter, Markus},
  title = {Incrementalizing Lattice-Based Program Analyses in Datalog},
  year = {2018},
  issue_date = {November 2018},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {2},
  number = {OOPSLA},
  url = {https://doi.org/10.1145/3276509},
  doi = {10.1145/3276509},
  abstract = {Program analyses detect errors in code, but when code changes frequently as in an IDE, repeated re-analysis from-scratch is unnecessary: It leads to poor performance unless we give up on precision and recall. Incremental program analysis promises to deliver fast feedback without giving up on precision or recall by deriving a new analysis result from the previous one. However, Datalog and other existing frameworks for incremental program analysis are limited in expressive power: They only support the powerset lattice as representation of analysis results, whereas many practically relevant analyses require custom lattices and aggregation over lattice values. To this end, we present a novel algorithm called DRedL that supports incremental maintenance of recursive lattice-value aggregation in Datalog. The key insight of DRedL is to dynamically recognize increasing replacements of old lattice values by new ones, which allows us to avoid the expensive deletion of the old value. We integrate DRedL into the analysis framework IncA and use IncA to realize incremental implementations of strong-update points-to analysis and string analysis for Java. As our performance evaluation demonstrates, both analyses react to code changes within milliseconds.},
  journal = {Proc. ACM Program. Lang.},
  month = oct,
  articleno = {139},
  numpages = {29},
  keywords = {Incremental Computing, Static Analysis, Domain-Specific Language, Lattice, Datalog, Language Workbench}
}

@inproceedings{lawall10coccinelle,
  TITLE = {{Finding Error Handling Bugs in OpenSSL Using Coccinelle}},
  AUTHOR = {Lawall, Julia and Laurie, Ben and Hansen, Ren{\'e} Rydhof and Palix, Nicolas and Muller, Gilles},
  URL = {https://hal.archives-ouvertes.fr/hal-00940375},
  BOOKTITLE = {{European Dependable Computing Conference}},
  ADDRESS = {Valencia, Spain},
  PAGES = {191-196},
  YEAR = {2010},
  MONTH = Apr,
  DOI = {10.1109/EDCC.2010.31},
  KEYWORDS = {Software quality ; Software evolution ; Static code analysis},
  HAL_ID = {hal-00940375},
  HAL_VERSION = {v1},
}

@InProceedings{falconer2007deepweaver,
  author="Falconer, Henry
    and Kelly, Paul H. J.
    and Ingram, David M.
    and Mellor, Michael R.
    and Field, Tony
    and Beckmann, Olav",
  editor="Krishnamurthi, Shriram
    and Odersky, Martin",
  title="A Declarative Framework for Analysis and Optimization",
  booktitle="Compiler Construction",
  year="2007",
  publisher="Springer Berlin Heidelberg",
  address="Berlin, Heidelberg",
  pages="218--232",
  abstract="DeepWeaver-1 is a tool supporting cross-cutting program analysis and transformation components, called ``weaves''. Like an aspect, a DeepWeaver weave consists of a query part, and a part which may modify code. DeepWeaver's query language is based on Prolog, and provides access to data-flow and control-flow reachability analyses. DeepWeaver provides a declarative way to access the internal structure of methods, and supports cross-cutting weaves which operate on code blocks from different parts of the codebase simultaneously. DeepWeaver operates at the level of bytecode, but offers predicates to extract structured control flow constructs. This paper motivates the design, and demonstrates some of its power, using a sequence of examples including performance profiling and domain-specific performance optimisations for database access and remote method invocation.",
  isbn="978-3-540-71229-9"
}

@book{copeland2005pmd,
  title={PMD applied},
  author={Copeland, Tom},
  volume={10},
  year={2005},
  publisher={Centennial Books Arexandria, Va, USA}
}

@inproceedings{visser2002concretesyntax,
  author = {Visser, Eelco},
  title = {Meta-Programming with Concrete Object Syntax},
  year = {2002},
  isbn = {3540442847},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  abstract = {Meta programs manipulate structured representations, i.e., abstract syntax trees, of programs. The conceptual distance between the concrete syntax meta-programmers use to reason about programs and the notation for abstract syntax manipulation provided by general purpose (meta-) programming languages is too great for many applications. In this paper it is shown how the syntax definition formalism SDF can be employed to fit any meta-programming language with concrete syntax notation for composing and analyzing object programs. As a case study, the addition of concrete syntax to the program transformation language Stratego is presented. The approach is then generalized to arbitrary meta-languages.},
  booktitle = {Proceedings of the 1st ACM SIGPLAN/SIGSOFT Conference on Generative Programming and Component Engineering},
  pages = {299–315},
  numpages = {17},
  series = {GPCE '02}
}

@article{visser04stratego,
  author = "E. Visser",
  title = "{P}rogram {T}ransformation with {S}tratego/{XT}: {R}ules, {S}trategies, {T}ools, and
    {S}ystems in {Stratego/XT} 0.9",
  journal = "Lecture Notes in Computer Science",
  volume = "3016",
  pages = "216--238",
  month = "June",
  year = "2004",
  editor = "C. Lengauer et al.",
  url = "citeseer.ist.psu.edu/article/visser04program.html" }

@inproceedings{reps1995ifds,
  title={Precise interprocedural dataflow analysis via graph reachability},
  author={Reps, Thomas and Horwitz, Susan and Sagiv, Mooly},
  booktitle={Proceedings of the 22nd ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
  pages={49--61},
  year={1995}
}
@inproceedings{reichenbach2021ticks,
  author = {Reichenbach, Christoph},
  booktitle = {Proceedings of the 43rd International Conference on Software Engineering: New Ideas and Emerging Results Track},
  location = {Virtual},
  title = {{Software Ticks Need No Specifications}},
  year = {2021}
}


@InProceedings{DaCapo:paper,
  title={The {DaCapo} Benchmarks: {J}ava Benchmarking Development and Analysis},
  author={Blackburn, S. M. and Garner, R. and Hoffman, C. and Khan, A. M.
      and McKinley, K. S. and Bentzur, R. and Diwan, A. and Feinberg, D.
      and Frampton, D. and Guyer, S. Z. and Hirzel, M. and Hosking, A.
      and Jump, M. and Lee, H. and Moss, J. E. B. and Phansalkar, A.
      and Stefanovi\'{c}, D. and {VanDrunen}, T. and von~Dincklage, D.
      and Wiedermann, B.},
  booktitle = {OOPSLA '06: Proceedings of the 21st annual ACM SIGPLAN conference on Object-Oriented Programing, Systems, Languages, and Applications},
  month = oct,
  year = {2006},
  pages = {169--190},
  location = {Portland, OR, USA},
  doi = {http://doi.acm.org/10.1145/1167473.1167488},
  publisher = {ACM Press},
  address = {New York, NY, USA},
}

@phdthesis{oqvist2018contributions,
  title={Contributions to Declarative Implementation of Static Program Analysis},
  author={{\"O}qvist, Jesper},
  year={2018},
  school={Lund University}
}

@inproceedings{jourdan84,
  author    = {Martin Jourdan},
  editor    = {Manfred Paul and
               Bernard Robinet},
  title     = {An Optimal-time Recursive Evaluator for Attribute Grammars},
  booktitle = {International Symposium on Programming, 6th Colloquium, Toulouse,
               France, April 17-19, 1984, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {167},
  pages     = {167--178},
  publisher = {Springer},
  year      = {1984},
  url       = {https://doi.org/10.1007/3-540-12925-1\_37},
  doi       = {10.1007/3-540-12925-1\_37},
  timestamp = {Tue, 14 May 2019 10:00:35 +0200},
  biburl    = {https://dblp.org/rec/conf/programm/Jourdan84.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{piskachev2021secucheck,
  title        = {SecuCheck: Engineering configurable taint analysis for software developers},
  author       = {Piskachev, Goran and Krishnamurthy, Ranjith and Bodden, Eric},
  booktitle    = {2021 IEEE 21st International Working Conference on Source Code Analysis and Manipulation (SCAM)},
  pages        = {24--29},
  year         = {2021},
  organization = {IEEE}
}
@article{10.1145/2666356.2594299,
  author     = {Arzt, Steven and Rasthofer, Siegfried and Fritz, Christian and Bodden, Eric and Bartel, Alexandre and Klein, Jacques and Le Traon, Yves and Octeau, Damien and McDaniel, Patrick},
  title      = {FlowDroid: Precise Context, Flow, Field, Object-Sensitive and Lifecycle-Aware Taint Analysis for Android Apps},
  year       = {2014},
  issue_date = {June 2014},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {49},
  number     = {6},
  issn       = {0362-1340},
  url        = {https://doi.org/10.1145/2666356.2594299},
  doi        = {10.1145/2666356.2594299},
  abstract   = {Today's smartphones are a ubiquitous source of private and confidential data. At the same time, smartphone users are plagued by carelessly programmed apps that leak important data by accident, and by malicious apps that exploit their given privileges to copy such data intentionally. While existing static taint-analysis approaches have the potential of detecting such data leaks ahead of time, all approaches for Android use a number of coarse-grain approximations that can yield high numbers of missed leaks and false alarms.In this work we thus present FlowDroid, a novel and highly precise static taint analysis for Android applications. A precise model of Android's lifecycle allows the analysis to properly handle callbacks invoked by the Android framework, while context, flow, field and object-sensitivity allows the analysis to reduce the number of false alarms. Novel on-demand algorithms help FlowDroid maintain high efficiency and precision at the same time.We also propose DroidBench, an open test suite for evaluating the effectiveness and accuracy of taint-analysis tools specifically for Android apps. As we show through a set of experiments using SecuriBench Micro, DroidBench, and a set of well-known Android test applications, FlowDroid finds a very high fraction of data leaks while keeping the rate of false positives low. On DroidBench, FlowDroid achieves 93% recall and 86% precision, greatly outperforming the commercial tools IBM AppScan Source and Fortify SCA. FlowDroid successfully finds leaks in a subset of 500 apps from Google Play and about 1,000 malware apps from the VirusShare project.},
  journal    = {SIGPLAN Not.},
  month      = {jun},
  pages      = {259–269},
  numpages   = {11}
}

@inproceedings{flowDroid,
  author    = {Arzt, Steven and Rasthofer, Siegfried and Fritz, Christian and Bodden, Eric and Bartel, Alexandre and Klein, Jacques and Le Traon, Yves and Octeau, Damien and McDaniel, Patrick},
  title     = {FlowDroid: Precise Context, Flow, Field, Object-Sensitive and Lifecycle-Aware Taint Analysis for Android Apps},
  year      = {2014},
  isbn      = {9781450327848},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2594291.2594299},
  doi       = {10.1145/2594291.2594299},
  abstract  = {Today's smartphones are a ubiquitous source of private and confidential data. At the same time, smartphone users are plagued by carelessly programmed apps that leak important data by accident, and by malicious apps that exploit their given privileges to copy such data intentionally. While existing static taint-analysis approaches have the potential of detecting such data leaks ahead of time, all approaches for Android use a number of coarse-grain approximations that can yield high numbers of missed leaks and false alarms.In this work we thus present FlowDroid, a novel and highly precise static taint analysis for Android applications. A precise model of Android's lifecycle allows the analysis to properly handle callbacks invoked by the Android framework, while context, flow, field and object-sensitivity allows the analysis to reduce the number of false alarms. Novel on-demand algorithms help FlowDroid maintain high efficiency and precision at the same time.We also propose DroidBench, an open test suite for evaluating the effectiveness and accuracy of taint-analysis tools specifically for Android apps. As we show through a set of experiments using SecuriBench Micro, DroidBench, and a set of well-known Android test applications, FlowDroid finds a very high fraction of data leaks while keeping the rate of false positives low. On DroidBench, FlowDroid achieves 93% recall and 86% precision, greatly outperforming the commercial tools IBM AppScan Source and Fortify SCA. FlowDroid successfully finds leaks in a subset of 500 apps from Google Play and about 1,000 malware apps from the VirusShare project.},
  booktitle = {Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  pages     = {259–269},
  numpages  = {11},
  location  = {Edinburgh, United Kingdom},
  series    = {PLDI '14}
}

@inproceedings{cousot2005astree,
  title        = {The ASTR{\'E}E analyzer},
  author       = {Cousot, Patrick and Cousot, Radhia and Feret, J{\'e}r{\^o}me and Mauborgne, Laurent and Min{\'e}, Antoine and Monniaux, David and Rival, Xavier},
  booktitle    = {European Symposium on Programming},
  pages        = {21--30},
  year         = {2005},
  organization = {Springer}
}

@inbook{Blanchet2002,
  author    = {Blanchet, Bruno
               and Cousot, Patrick
               and Cousot, Radhia
               and Feret, J{\'e}r{\^o}me
               and Mauborgne, Laurent
               and Min{\'e}, Antoine
               and Monniaux, David
               and Rival, Xavier},
  editor    = {Mogensen, Torben {\AE}.
               and Schmidt, David A.
               and Sudborough, I. Hal},
  title     = {Design and Implementation of a Special-Purpose Static Program Analyzer for Safety-Critical Real-Time Embedded Software},
  booktitle = {The Essence of Computation: Complexity, Analysis, Transformation},
  year      = {2002},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {85--108},
  abstract  = {We report on a successful preliminary experience in the design and implementation of a special-purpose Abstract Interpretation based static program analyzer for the verification of safety critical embedded real-time software. The analyzer is both precise (zero false alarm in the considered experiment) and efficient (less than one minute of analysis for 10,000 lines of code). Even if it is based on a simple interval analysis, many features have been added to obtain the desired precision: expansion of small arrays, widening with several thresholds, loop unrolling, trace partitioning, relations between loop counters and other variables. The efficiency of the tool mainly comes from a clever representation of abstract environments based on balanced binary search trees.},
  isbn      = {978-3-540-36377-4},
  doi       = {10.1007/3-540-36377-7_5},
  url       = {https://doi.org/10.1007/3-540-36377-7_5}
}



@article{rice1953classes,
  title     = {Classes of recursively enumerable sets and their decision problems},
  author    = {Rice, Henry Gordon},
  journal   = {Transactions of the American Mathematical society},
  volume    = {74},
  number    = {2},
  pages     = {358--366},
  year      = {1953},
  publisher = {JSTOR}
}


@article{SLOANE2010205,
  title    = {A Pure Object-Oriented Embedding of Attribute Grammars},
  journal  = {Electronic Notes in Theoretical Computer Science},
  volume   = {253},
  number   = {7},
  pages    = {205-219},
  year     = {2010},
  note     = {Proceedings of the Ninth Workshop on Language Descriptions Tools and Applications (LDTA 2009)},
  issn     = {1571-0661},
  doi      = {https://doi.org/10.1016/j.entcs.2010.08.043},
  url      = {https://www.sciencedirect.com/science/article/pii/S1571066110001222},
  author   = {Anthony M. Sloane and Lennart C.L. Kats and Eelco Visser},
  keywords = {language processing, compilers, domain-specific languages},
  abstract = {Attribute grammars are a powerful specification paradigm for many language processing tasks, particularly semantic analysis of programming languages. Recent attribute grammar systems use dynamic scheduling algorithms to evaluate attributes by need. In this paper, we show how to remove the need for a generator, by embedding a dynamic approach in a modern, object-oriented programming language to implement a small, lightweight attribute grammar library. The Kiama attribution library has similar features to current generators, including cached, uncached, circular, higher-order and parameterised attributes, and implements new techniques for dynamic extension and variation of attribute equations. We use the Scala programming language because of its combination of object-oriented and functional features, support for domain-specific notations and emphasis on scalability. Unlike generators with specialised notation, Kiama attribute grammars use standard Scala notations such as pattern-matching functions for equations and mixins for composition. A performance analysis shows that our approach is practical for realistic language processing.}
}

@article{VANWYK201039,
  title    = {Silver: An extensible attribute grammar system},
  journal  = {Science of Computer Programming},
  volume   = {75},
  number   = {1},
  pages    = {39-54},
  year     = {2010},
  note     = {Special Issue on ETAPS 2006 and 2007 Workshops on Language Descriptions, Tools, and Applications (LDTA ’06 and ’07)},
  issn     = {0167-6423},
  doi      = {https://doi.org/10.1016/j.scico.2009.07.004},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167642309001099},
  author   = {Eric {Van Wyk} and Derek Bodin and Jimin Gao and Lijesh Krishnan},
  keywords = {Extensible languages, Extensible compilers, Attribute grammars, Forwarding, Silver attribute grammar system},
  abstract = {Attribute grammar specification languages, like many domain-specific languages, offer significant advantages to their users, such as high-level declarative constructs and domain-specific analyses. Despite these advantages, attribute grammars are often not adopted to the degree that their proponents envision. One practical obstacle to their adoption is a perceived lack of both domain-specific and general purpose language features needed to address the many different aspects of a problem. Here we describe Silver, an extensible attribute grammar specification system, and show how it can be extended with general purpose features such as pattern matching and domain-specific features such as collection attributes and constructs for supporting data-flow analysis of imperative programs. The result is an attribute grammar specification language with a rich set of language features. Silver is implemented in itself by a Silver attribute grammar and utilizes forwarding to implement the extensions in a cost-effective manner.}
}

@article{piskachev2022far,
  title   = {How far are German companies in improving security through static program analysis tools?},
  author  = {Piskachev, Goran and Dziwok, Stefan and Koch, Thorsten and Merschjohan, Sven and Bodden, Eric},
  journal = {arXiv preprint arXiv:2208.06136},
  year    = {2022}
}

@misc{rusling1999linux,
  title  = {The linux kernel},
  author = {Rusling, David A},
  year   = {1999}
}

@article{madsen2016programming,
  title={Programming a Dataflow Analysis in Flix},
  author={Madsen, Magnus and Yee, Ming-Ho and Lhot{\'a}k, Ondrej},
  journal={Tools for Automatic Program Analysis (TAPAS)},
  year={2016}
}

